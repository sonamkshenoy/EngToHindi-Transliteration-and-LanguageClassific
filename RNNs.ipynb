{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOtx6NFL+LkpoYXEocfq37g"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JseoduTJFYcx",
        "colab_type": "code",
        "outputId": "d51f58f6-8e10-4b96-8eb3-255082c7890c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from io import open\n",
        "import os, string, random, time, math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX5B2pjlFzEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHysBclRF27-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As0Y_XQPF9aV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output # clears output of cell, say to show multiple plots but show only most recent one"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOJxIp9CGfPo",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suHpYDj-Gl0s",
        "colab_type": "text"
      },
      "source": [
        "Task: To predict nationality a name (varying length) belongs to.  \n",
        "Therefore, sequence model since sequence of characters, have to encode each character and predict one class (usual softmax) \n",
        "\n",
        "  \n",
        "\n",
        "---\n",
        "\n",
        "  \n",
        "Sequence Tasks:  \n",
        "Sequence to Class (input is sequence, output is just one class) - what we are doing currently   \n",
        "Sequence to Sequence Type 1 (input is sequence, output is sequence where there is an output corresponding to each item in the input e.g. POS)  \n",
        "Sequence to Class (input is sequence, output is sequence, but there is not one output for each word, but be more or less e.g. transliteration - converting english word to hindi)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJYssHQlGf8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwi82u7QICNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "languages = []\n",
        "data = []\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "with open('name2lang.txt','r') as f:\n",
        "  for line in f:\n",
        "    line = line.split(',')\n",
        "    name = line[0].strip()\n",
        "    lang = line[1].strip()\n",
        "    if not lang in languages:\n",
        "      languages.append(lang)\n",
        "    X.append(name)\n",
        "    y.append(lang)\n",
        "    data.append((name, lang))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIyM_zA-JQuL",
        "colab_type": "code",
        "outputId": "96415088-160c-4020-bf7d-46582d539061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "n_languages = len(languages)\n",
        "print(n_languages)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZnqf841JYn_",
        "colab_type": "text"
      },
      "source": [
        "There are 18 languages in this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba1oJ1DQJwD7",
        "colab_type": "code",
        "outputId": "e7c893e7-5a3b-4626-c6da-74df997bc923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(languages)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Portuguese', 'Irish', 'Spanish', 'Vietnamese', 'Chinese', 'Greek', 'Czech', 'Dutch', 'Japanese', 'French', 'German', 'Scottish', 'English', 'Russian', 'Polish', 'Arabic', 'Korean', 'Italian']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjRUUc78JW6Q",
        "colab_type": "code",
        "outputId": "64ecf15b-aac2-4500-d0ba-454549132e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(data[0:10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Abreu', 'Portuguese'), ('Albuquerque', 'Portuguese'), ('Almeida', 'Portuguese'), ('Alves', 'Portuguese'), ('Araujo', 'Portuguese'), ('Araullo', 'Portuguese'), ('Barros', 'Portuguese'), ('Basurto', 'Portuguese'), ('Belo', 'Portuguese'), ('Cabral', 'Portuguese')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moN5zPJ-JiSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIZZk9K3J30c",
        "colab_type": "text"
      },
      "source": [
        "# Train-test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL7IevTbJ4Nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 61, stratify = y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_PdNkrFK1ac",
        "colab_type": "text"
      },
      "source": [
        "(Both X and y should have the same dimensions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNLNGqZnKSne",
        "colab_type": "code",
        "outputId": "2bae836f-fbd8-4356-bd44-adb27a19e386",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(X_train[:20])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Kaufman', 'Chandler', 'Agar', 'Essa', 'Makhagonov', 'Prokudin', 'Porus', 'Lowry', 'Nezvigin', 'Cove', 'Peach', 'Newlands', 'Bajov', 'Chukhnovsky', 'Naser', 'Gaspirovich', 'Vykhodtsev', 'Chuvilkin', 'Maksimchuk', 'Dandy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaisbKIhLBXY",
        "colab_type": "code",
        "outputId": "24a30096-aade-43e8-9982-f2de15c2a1a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(len(X_train), len(X_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16040 4010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXYqNsBxLFRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBn7lQ90LMiJ",
        "colab_type": "text"
      },
      "source": [
        "# Encoding names and languages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jad2LUTILVh0",
        "colab_type": "text"
      },
      "source": [
        "Since output is a class, can use one hot encoding easily.  \n",
        "But input is a sequence, so have to encode each character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRYjpnk5LOnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list of all characters possible in a name\n",
        "all_letters = string.ascii_letters + \" .,;\"\n",
        "n_letters = len(all_letters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx61BiXULyBU",
        "colab_type": "text"
      },
      "source": [
        "Encode the name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3DE9m7GLrBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let encoding be one hot encoding for each character, where the hot bit is the index of the char in the above string of all letters\n",
        "def name_rep(name):\n",
        "  rep = torch.zeros(len(name), 1, n_letters)\n",
        "  for index, letter in enumerate(name):\n",
        "    pos = all_letters.find(letter)\n",
        "    rep[index][0][pos] = 1\n",
        "  return rep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbUw7ngUMt_Z",
        "colab_type": "text"
      },
      "source": [
        "Encode the language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXRpPvQfMV1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Don't require one hot encoding, just label sufficient\n",
        "def lang_rep(lang):\n",
        "  return torch.tensor([languages.index(lang)], dtype = torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOnKrgj3M_cW",
        "colab_type": "code",
        "outputId": "9ec11bef-f699-477f-9424-9b51e9db2dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "name_rep('Almeida')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaYe84s3NaHG",
        "colab_type": "text"
      },
      "source": [
        "7 letters in name, so 7 vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUMWrn8GNEtq",
        "colab_type": "code",
        "outputId": "f70946fb-ab73-4598-a45e-89dc57886d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "lang_rep('Dutch')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIVBLiX0Ni2Q",
        "colab_type": "text"
      },
      "source": [
        "Label of Dutch in languages array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLnwCHSSNRQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCqYCaSdNrkg",
        "colab_type": "text"
      },
      "source": [
        "# Basic Visualisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKEVu3G4Nzo9",
        "colab_type": "text"
      },
      "source": [
        "Distribution of languages in our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVLJnDUrNs9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = {}\n",
        "\n",
        "for l in languages:\n",
        "  count[l] = 0\n",
        "for d in data:\n",
        "  count[d[1]] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRJA48r3N_oo",
        "colab_type": "code",
        "outputId": "139e808b-978c-4fc9-a3f6-c8caad341284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(count)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Portuguese': 74, 'Irish': 232, 'Spanish': 298, 'Vietnamese': 73, 'Chinese': 268, 'Greek': 203, 'Czech': 519, 'Dutch': 297, 'Japanese': 991, 'French': 277, 'German': 724, 'Scottish': 100, 'English': 3668, 'Russian': 9384, 'Polish': 139, 'Arabic': 2000, 'Korean': 94, 'Italian': 709}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkSI0f0COErW",
        "colab_type": "text"
      },
      "source": [
        "Highly non-uniform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-uNbA3HOAfC",
        "colab_type": "code",
        "outputId": "34d06bf2-fdb0-4526-c66f-483187be3880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "plt_ = sns.barplot(list(count.keys()), list(count.values()))\n",
        "plt_.set_xticklabels(plt_.get_xticklabels(), rotation = 90)\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDtdhBFxOxMx",
        "colab_type": "text"
      },
      "source": [
        "Model might learn Russian names too well and predict them well since lots of data, but less training on the rest.  \n",
        "Hence, have to see not the overall accuracy, but accuracy for each language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEvPNdeFPK6Q",
        "colab_type": "text"
      },
      "source": [
        "Therefore, baseline is not to pick names from each language equally, but pick according to the distribution, more for Russian."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4wZ2VSPPZwb",
        "colab_type": "text"
      },
      "source": [
        "Thus, baseline testing is easy, but training isn't"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58IbURhoOa1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF2otzAwPVfh",
        "colab_type": "text"
      },
      "source": [
        "# Basic network and testing inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJDvL-wkPYoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN_net(nn.Module):\n",
        "  # just setting up layers, not computing anything\n",
        "  # input_size : size of encoding of one character in the input (i.e. number of letters, here)\n",
        "  # hidden_size : the hidden layer though looks like one (for a single unit of the RNN) can be any number of layers\n",
        "  # output_size : the number of labels (number of languages, here)\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(RNN_net, self).__init__() # parent's (NN's) init\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # both below are Linear (fully connected)\n",
        "    # just mention input size and output size. Weights, biases etc taken care of by library (encapsulated)\n",
        "\n",
        "    # i2h is the intersection of the previous character's output and current input character, hence concatenation of hidden size (previous input size - coming out of hidden layer) and input size (current input size). Output should of course be hidden size again\n",
        "    self.i2h = nn.Linear(input_size + hidden_size, hidden_size) # \"concatenation (i.e. both preserved)\", not addition (corresponding elements added), of input and hidden of previous\n",
        "    \n",
        "    # i2o is the intersection of the h and the output o. (the final output layer part). Input is the computed h (hidden_size) and the current input (input_size)\n",
        "    self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "\n",
        "    # Note only 1 layer used for both above transformations, but can have more\n",
        "    \n",
        "    # Final output\n",
        "    self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "\n",
        "  # where layers are put to use\n",
        "  def forward(self, input_, hidden):\n",
        "    combined = torch.cat((input_, hidden), 1) # concatenate hidden and input in right direction (1, here. 1 means column always in a 2D vector, and usually \"along\". So concatenate - NOT ADDS - along row. Next to each other)\n",
        "    hidden = self.i2h(combined) # comput hidden value\n",
        "    output = self.i2o(combined) # compute output\n",
        "    output = self.softmax(output) # compute softmax\n",
        "    return output, hidden # return both output and hidden\n",
        "\n",
        "  # the first time (beginning of sequence) the hidden vector is not present, so call this function the first time\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(1, self.hidden_size) # Randomly initialised to 1, can use something else too"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67vAe0Kblyty",
        "colab_type": "text"
      },
      "source": [
        "Now, instantiate model (hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkXTHyqYlyWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of hidden layers\n",
        "n_hidden = 128 # compromise between overfitting and having less data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K57M2vKNTrrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = RNN_net(n_letters, n_hidden, n_languages)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm_XnQfvnFQE",
        "colab_type": "text"
      },
      "source": [
        "Now, unlike CNNs, infer before testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-Xp-lKKmiRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def infer(net, name):\n",
        "  net.eval() # put network in eval mode during inference (not train mode)\n",
        "  name_ohe = name_rep(name) # one hot encoding\n",
        "  hidden = net.init_hidden() # initialise hidden vector for first instance of RNN, using encapsulated function\n",
        "\n",
        "  # name_ohe size = (n_letters, 1, sizeofword)\n",
        "  # here, iterating through each character. For each character in OHE, invoking forward (\"net\")\n",
        "  for i in range(name_ohe.size()[0]):\n",
        "\n",
        "    # name_ohe[i] = a vector of first character of OHE of all letters in the word (since RNN always expects a vector - 1 dimension)\n",
        "    # note the instantiated hidden layer is used only once. Thereafter, the new computed hidden used each time\n",
        "    # \"output\" for each iteration is the output of FFNN of one RNN unit, for that iteration (thus, overwritten each time). Hence at end of word, \"output\" contains the output of the final unit of the RNN (answer)\n",
        "    \n",
        "    output, hidden = net(name_ohe[i], hidden)\n",
        "\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K4ORDtlqp8_",
        "colab_type": "text"
      },
      "source": [
        "While inferring, an optimisation could be done, by removing softmax layer in the \"forward\" function of the model, since argmax will remain same before and after an argmax. It's only a computationally heavy operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDUp1n1NpwRy",
        "colab_type": "code",
        "outputId": "5b4b5aec-1bb1-4206-d44c-76ee34a25479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "output = infer(net, X_train[0])\n",
        "\n",
        "print(X_train[0])\n",
        "\n",
        "# Softmax returned so argmax\n",
        "index = torch.argmax(output)\n",
        "print(output)\n",
        "print(index)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kaufman\n",
            "tensor([[-2.9999, -2.8400, -2.9612, -2.8802, -2.7719, -2.9317, -2.8997, -2.8149,\n",
            "         -2.9730, -2.9554, -2.8533, -2.9337, -2.9000, -2.7735, -2.9039, -2.8335,\n",
            "         -2.9503, -2.8889]], grad_fn=<LogSoftmaxBackward>)\n",
            "tensor(4, grad_fn=<NotImplemented>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjYbVE7PrAVX",
        "colab_type": "text"
      },
      "source": [
        "Says Kaufman belongs to nationality of index 4.  \n",
        "Note: without training, outputs if all classes are roughly same - doesn't know how to differentiate yet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPiNVfDJqGmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P539BqXQrgPH",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLd5PlQhrhD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# just to generate random inputs from the dataset since in the data, languages are present in an ordered manner\n",
        "def dataloader(npoints, X_, y_):\n",
        "  to_ret = []\n",
        "  for i in range(npoints):\n",
        "    index_ = np.random.randint(len(X_))\n",
        "    name, lang = X_[index_], y_[index_]\n",
        "    to_ret.append((name, lang, name_rep(name), lang_rep(lang))) # append() takes exactly one argument so append as tuple\n",
        "  return to_ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6zWhSohuEAe",
        "colab_type": "code",
        "outputId": "27095de9-55f6-41eb-e147-98abd19fd765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dataloader(2, X_train, y_train)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Tchekhonin',\n",
              "  'Russian',\n",
              "  tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]]]),\n",
              "  tensor([13])),\n",
              " ('Baistryutchenko',\n",
              "  'Russian',\n",
              "  tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]],\n",
              "  \n",
              "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "            0., 0., 0., 0., 0.]]]),\n",
              "  tensor([13]))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QHufzt9uOAl",
        "colab_type": "text"
      },
      "source": [
        "Output: Name, lang, name_enc, lang_enc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFPNrTg2sa0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generally classification eval done using top-k accuracy (ground truth in top-k predictions)\n",
        "def eval(net, n_points, k, X_, y_):\n",
        "\n",
        "  data_ = dataloader(n_points, X_, y)\n",
        "  correct = 0\n",
        "\n",
        "  for name, language, name_ohe, lang_rep in data_:\n",
        "\n",
        "    output = infer(net, name)\n",
        "    val, indices = output.topk(k) # topk - PyTorch function\n",
        "\n",
        "    if lang_rep in indices:\n",
        "      correct +=1\n",
        "\n",
        "  accuracy = correct/n_points\n",
        "  return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_QNY5MKtSAW",
        "colab_type": "code",
        "outputId": "d6c5c762-b411-4da3-bec3-ffeab6cb2e8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "eval(net, 100, 1, X_test, y_test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ41yysLtdMW",
        "colab_type": "code",
        "outputId": "c9d50303-4413-422b-a374-8451a35bd0a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "eval(net, 100, 10, X_test, y_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp7NVin7vCvJ",
        "colab_type": "text"
      },
      "source": [
        "Obviously greater for higher k since almost all languages predicted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5-A_qHfu-Kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_QJlZCjvdr_",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQGh8fh5viuQ",
        "colab_type": "text"
      },
      "source": [
        "### Basic setup\n",
        "(for just one batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE7phZSHvkrw",
        "colab_type": "text"
      },
      "source": [
        "Define loss function and backpropagation  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOSQ3zox1mYE",
        "colab_type": "text"
      },
      "source": [
        "Computing output several times and then backpropagating through them. Thus, going through same network many times. But all this book keeping (of all params) done for us by PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO8qrxlbveUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, opt, criterion, n_points): # criterion = loss function\n",
        "\n",
        "  # set all params to 0, in case they were retained from an earlier training\n",
        "  opt.zero_grad()\n",
        "  total_loss = 0\n",
        "\n",
        "  # choose random points\n",
        "  data_ = dataloader(n_points, X_train, y_train)\n",
        "\n",
        "  for name, language, name_ohe, lang_rep in data_:\n",
        "\n",
        "    hidden = net.init_hidden()\n",
        "\n",
        "    # pass each character\n",
        "    # creating computational graph (i.e. the params, output for each individual unit of the RNN - all being stored by PyTorch). While backpropagating, we backpropagate through all of these\n",
        "    for i in range(name_ohe.size()[0]):\n",
        "      output, hidden = net(name_ohe[i], hidden)\n",
        "\n",
        "    loss = criterion(output, lang_rep)\n",
        "\n",
        "    # computing gradients (a LOT done in this step behind scenes)\n",
        "    loss.backward(retain_graph = True)\n",
        "\n",
        "    total_loss += loss\n",
        "\n",
        "  # update params using the grad computed using loss.backward \n",
        "  # Just one step here\n",
        "  opt.step()\n",
        "\n",
        "  # divide since we aggregated loss for all points\n",
        "  return total_loss/n_points"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiW7TjEXzFRy",
        "colab_type": "text"
      },
      "source": [
        "The above is for one batch of n_points. For all these points, computing one set of gradients and updating only once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qifhCnx6w5BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss() # negative log likelihood loss because using softmax\n",
        "opt = optim.SGD(net.parameters(), lr = 0.01, momentum = 0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PkgkUnSxE7D",
        "colab_type": "code",
        "outputId": "95771473-12a7-4bc7-b43a-f23c4271ca52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "%%time\n",
        "train(net, opt, criterion, 200)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 256 ms, sys: 31.1 ms, total: 287 ms\n",
            "Wall time: 388 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.8585, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz8eD2Shz0So",
        "colab_type": "code",
        "outputId": "bf79e916-d447-4268-bc16-19edb1a016bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Top-1\n",
        "eval(net, 1000, 1, X_test, y_test)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YDbTfrm0FDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4guzIp-u2J2F",
        "colab_type": "text"
      },
      "source": [
        "### Full training setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhcWxeOlAwbf",
        "colab_type": "text"
      },
      "source": [
        "1 function to train just a batch  \n",
        "1 cell to encapsulate all the hyperparameters (optimizer etc)  \n",
        "1 function for the training setup (which takes all hyperparameters as arguments) - this function doesn't contain all details - just ML flow with parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE39Kc3b2LiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq = 5):\n",
        "  # display every 5 iterations\n",
        "\n",
        "  criterion = nn.NLLLoss()\n",
        "  # Note: If last function is softmax in model, then HAVE to use NLLLoss, else if softmax not mentioned, can use Cross Entropy Loss Function\n",
        "  # As mentioned earlier, don't have to use softmax since it is computationally heavy, and all we need is the top-k. But required when inferring. So can use softmax.\n",
        "  \n",
        "  opt = optim.SGD(net.parameters(), lr = lr, momentum = momentum)\n",
        "\n",
        "  loss_arr = np.zeros(n_batches + 1)\n",
        "\n",
        "  for i in range(n_batches):\n",
        "    # call to 'train' for each batch\n",
        "    loss_arr[i+1] = (loss_arr[i]*i + train(net, opt, criterion, batch_size))/(i+1)\n",
        "\n",
        "    if i%display_freq == display_freq-1:\n",
        "      clear_output(wait=True)\n",
        "\n",
        "      print(\"Iteration\",i,\"Top-1\", eval(net, len(X_test), 1, X_test, y_test), \"Top-2\", eval(net, len(X_test), 1, X_test, y_test))\n",
        "\n",
        "      plt.figure()\n",
        "      plt.plot(loss_arr[1:i], '-*')\n",
        "      plt.xlabel('Iteration')\n",
        "      plt.ylabel('Loss')\n",
        "      plt.show()\n",
        "      print(\"\\n\\n\")\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuBLOl9r3iiC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "9f77727e-8461-418f-c70d-fa1c3948254f"
      },
      "source": [
        "n_hidden = 128\n",
        "net = RNN_net(n_letters, n_hidden, n_languages)\n",
        "train_setup(net, lr = 0.0005, n_batches = 100, batch_size = 256)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 99 Top-1 0.010723192019950124 Top-2 0.010723192019950124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lTqW4tsCQNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAx5IvXXDoYh",
        "colab_type": "text"
      },
      "source": [
        "# LSTM Cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVY-d__-ELh4",
        "colab_type": "text"
      },
      "source": [
        "(In PyTorch docs, can see all the function definitions for SELECTIVE READ, SELECTIVE WRITE and SELECTIVE FORGET)   \n",
        "Should make function signatures same so that on changing LSTM_net to RNN_net, we don't have to change the arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_mXP-pzDnR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_net(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(LSTM_net, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.lstm_cell = nn.LSTM(input_size, hidden_size)\n",
        "    self.h2o = nn.Linear(hidden_size, output_size) # one linear (fully connected) layer, that computes the output (number of languages) from the hidden layer\n",
        "    self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "  def forward(self, input_, hidden):\n",
        "    # LSTM does computation of hidden state as well\n",
        "    # .view => reshape. -1 => flatten out whatever's remaining\n",
        "    # (can give several inputs simultanously (to benefit from vectorization, but not done here), number of batches, to flatten)\n",
        "    out, hidden = self.lstm_cell(input_.view(1, 1, -1), hidden)\n",
        "    output = self.h2o(hidden[0])\n",
        "    output = self.softmax(output)\n",
        "    return output.view(1, -1), hidden # flatten\n",
        "\n",
        "  # this time 2 tuples since - one for hidden state, and other for cell state\n",
        "  def init_hidden(self):\n",
        "    # (1, 1, self.hidden_size) -> (number of layers in LSTM cell, number of batches, size)\n",
        "    return (torch.zeros(1, 1, self.hidden_size), torch.zeros(1, 1, self.hidden_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlM9UvX1IneP",
        "colab_type": "text"
      },
      "source": [
        "Note: Batching implies two things:  \n",
        "1. Updating weight and bias, once for an entire batch, instead of updating for every record.  \n",
        "2. To improve performance.  \n",
        "The first one is what was done in RNN and here too. 2nd one later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkj7f6kPHLeT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "d8b9f3c8-f391-45ba-ee97-c887836ebdbd"
      },
      "source": [
        "# note the same code for RNN - of course have to change lr, batch size etc to suit to new model\n",
        "n_hidden = 128\n",
        "net = LSTM_net(n_letters, n_hidden, n_languages)\n",
        "train_setup(net, lr = 0.0005, n_batches = 100, batch_size = 256)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 99 Top-1 0.0 Top-2 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jdlOKeHHbF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSoIMA8iMavc",
        "colab_type": "text"
      },
      "source": [
        "# GRU Cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phi5BNP6MdED",
        "colab_type": "text"
      },
      "source": [
        "Fewer number of gates.  \n",
        "Everything (tanh, sigmoid, etc, etc) being done internally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXKgfl-yMcay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRU_net(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(GRU_net, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.gru_cell = nn.GRU(input_size, hidden_size)\n",
        "    self.h2o = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "  def forward(self, input_, hidden):\n",
        "    out, hidden = self.gru_cell(input_.view(1, 1, -1), hidden)\n",
        "    output = self.h2o(hidden[0])\n",
        "    output = self.softmax(output)\n",
        "    return output.view(1, -1), hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEMOM5XfOQ1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_hidden = 128\n",
        "net = GRU_net(n_letters, n_hidden, n_languages)\n",
        "train_setup(net, lr = 0.0005, n_batches = 100, batch_size = 256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc5SsBAYN02i",
        "colab_type": "text"
      },
      "source": [
        "Confusion matrix: (Square matrix, each side of size = number of languages). If ground truth was i, how many times we are classifying it as j. We want diagonal entries to be large for correct classification (will tell us more about top-k)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvyVv-VfPMY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}