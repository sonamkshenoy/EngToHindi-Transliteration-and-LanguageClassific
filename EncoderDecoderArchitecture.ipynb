{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EncoderDecoderArchitecture.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM65onGgZ6AmEvDPtmQMYWc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ewFbZLpa6Dm",
        "colab_type": "text"
      },
      "source": [
        "# Outline\n",
        "\n",
        "1. Data set and task\n",
        "2. Data processing XML files\n",
        "3. Why we need encoder decoder architecture\n",
        "4. Basic GRU based encoder decoder\n",
        "5. Adding attention\n",
        "6. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLYVFJufavdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YpfrGmEbobB",
        "colab_type": "code",
        "outputId": "4ec3e7fc-15d8-4a5f-9441-6b9d8bfee158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "# Visualisation tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlBBjyU8b324",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1YeJz5dcitT",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "476ASkj-clYp",
        "colab_type": "text"
      },
      "source": [
        "### Alphabets setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew944iDyeaxt",
        "colab_type": "text"
      },
      "source": [
        "As usual, convert first to numerical form so that model can process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoKmPaCce-7r",
        "colab_type": "text"
      },
      "source": [
        "### English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9_wc9lAcjp7",
        "colab_type": "code",
        "outputId": "ee727a0f-7a9d-425c-a06d-4f09d54939e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char:0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "  eng_alpha2index[alpha] = index+1\n",
        "\n",
        "# Same as:\n",
        "# for index, alpha in enumerate(eng_alphabets, 1):\n",
        "#   eng_alpha2index[alpha] = index\n",
        "\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4BcT4Yzez35",
        "colab_type": "text"
      },
      "source": [
        "### Hindi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ_ZADU-dHm0",
        "colab_type": "code",
        "outputId": "7675d6fa-9d40-4182-882f-3ad1e597182d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char : 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "  hindi_alpha2index[alpha] = index + 1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QbBoHqqgWEy",
        "colab_type": "text"
      },
      "source": [
        "Note: de in devanagiri in Hindi, though looks like one character (in Hindi), is actually 2 unicode characters : da and e (in hindi)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssw7bkbcgElo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqgjb2HWgIR3",
        "colab_type": "text"
      },
      "source": [
        "# Data Pre-processing helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "001Zhv85gLgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re # regular expressions\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters (alphabets and space)\n",
        "def cleanEnglishVocab(line):\n",
        "  line = line.replace('-',' ').replace(',',' ').upper() # '-' and ',' act as space\n",
        "  line = non_eng_letters_regex.sub('', line) # substitute all chars of non_eng_letters_regex present in line by nothing ('')\n",
        "  return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "  # print(line)\n",
        "  line = line.replace('-',' ').replace(',',' ')\n",
        "  cleaned_line = ''\n",
        "  for char in line:\n",
        "    if char in hindi_alpha2index or char == ' ':\n",
        "      cleaned_line += char\n",
        "  return cleaned_line.split() # mistake : gave it one indent more so always returned length 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpMaU2DUiNS9",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n3fovAdiI3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET # available in Python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EBkFmfbyUlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree = ET.parse('NEWS2012-Ref-EnHi-1000.xml')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNVUETo1z3kT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "77b4fec2-56a4-4429-e2a6-d0227362af43"
      },
      "source": [
        "root = tree.getroot()\n",
        "print(root)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Element 'TransliterationCorpus' at 0x7f5982be5ea8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVyqSEw_z4TG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "851c5d07-7bd4-4731-f281-b2c36ef49a09"
      },
      "source": [
        "root.tag"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'TransliterationCorpus'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfnf6WMa0gz5",
        "colab_type": "text"
      },
      "source": [
        "The root tag is named TransliterationCorpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCeLQPlb0a1j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "8af15cc2-70c7-431e-8f28-d0d872caec39"
      },
      "source": [
        "i = 0\n",
        "for child in root:\n",
        "    print(child.tag, child.attrib)\n",
        "    if i > 5:\n",
        "      break\n",
        "    i += 1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name {'ID': '1'}\n",
            "Name {'ID': '2'}\n",
            "Name {'ID': '3'}\n",
            "Name {'ID': '4'}\n",
            "Name {'ID': '5'}\n",
            "Name {'ID': '6'}\n",
            "Name {'ID': '7'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0ieeJwn0_-Q",
        "colab_type": "text"
      },
      "source": [
        "The next sub level tags are \"Name\" tags with \"ID\" attribute.  \n",
        "Similar to how a HTML tag div, has an attribute \"class\" or \"id\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0j0GsW81Tpo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "7b4b3aec-68f1-4cdc-a056-b0081a37b8ad"
      },
      "source": [
        "i = 0\n",
        "for elem in root.iter():\n",
        "    print(elem.tag)\n",
        "    if i > 11:\n",
        "      break\n",
        "    i += 1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TransliterationCorpus\n",
            "Name\n",
            "SourceName\n",
            "TargetName\n",
            "Name\n",
            "SourceName\n",
            "TargetName\n",
            "Name\n",
            "SourceName\n",
            "TargetName\n",
            "Name\n",
            "SourceName\n",
            "TargetName\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viobQC0t1xOa",
        "colab_type": "text"
      },
      "source": [
        "The above lists the inner elements.  \n",
        "The inner structure is :  \n",
        "TransliterationCorpus -> Name -> SourceName at same level as TargetName"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSYQ8lzJ2SXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "a0b36c78-0349-4ef0-a1f8-bedfd0b06251"
      },
      "source": [
        "# [(ele.tag, ele.attrib) for ele in root.iter(\"Name\")] : prints all attributes of Name tag\n",
        "# nextelem.tag or nextelem.attrib prints empty braces since this tag has no attributes\n",
        "\n",
        "i = 0\n",
        "for nextelem in root.iter(\"SourceName\"):\n",
        "  print(nextelem.text)\n",
        "  if i > 11:\n",
        "    break\n",
        "  i += 1"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aadhi\n",
            "Aakash\n",
            "Aap\n",
            "Aayasha\n",
            "Aayee\n",
            "Abduh\n",
            "Aberhart\n",
            "Abey\n",
            "Abou\n",
            "Abri\n",
            "Academy\n",
            "Accommodation\n",
            "Acorn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E6o0BKE3kND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "7085e482-2cd0-4c34-8f68-041613afd5aa"
      },
      "source": [
        "i = 0\n",
        "for nextelem in root.iter(\"TargetName\"):\n",
        "  print(nextelem.text)\n",
        "  if i > 11:\n",
        "    break\n",
        "  i += 1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "आधी\n",
            "आकाश\n",
            "आप\n",
            "आयशा\n",
            "आई\n",
            "अब्दुस\n",
            "एबरहर्ट\n",
            "अबेय\n",
            "अबू\n",
            "एब्री\n",
            "अकेडमी\n",
            "एकेडमी\n",
            "एकोमडेशन\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M4hyLxz3sqD",
        "colab_type": "text"
      },
      "source": [
        "Thus extracted English and corresponding Hindi from XML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LPJlN53zvMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransliterationLoader(Dataset): # extends Dataset, adding features of our own to it\n",
        "  def __init__(self, filename):\n",
        "    self.eng_words, self.hindi_words = self.readXMLDataset(filename)\n",
        "    self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "    random.shuffle(self.shuffle_indices)\n",
        "    self.shuffle_start_index = 0\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.eng_words)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.eng_words[idx], self.hindi_words[idx]\n",
        "\n",
        "  def readXMLDataset(self, filename):\n",
        "    transliterationCorpus = ET.parse(filename).getroot()\n",
        "    English_words = []\n",
        "    Hindi_words = []\n",
        "\n",
        "    for line in transliterationCorpus:\n",
        "      wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "      wordlist2 = cleanHindiVocab(line[1].text)\n",
        "      # print(wordlist1, '-', wordlist2)\n",
        "\n",
        "      # Skip noisy data i.e. where number of \"words\" (not \"characters\" in each word) is not the same in English and Hindi\n",
        "      # e.g. English: Stirling Smith Museum And Art Gallery, Hindi: स (4 words in English corresponding to one in Hindi)\n",
        "      if len(wordlist1) != len(wordlist2):\n",
        "        print(\"Skipping: \", line[0].text, '-', line[1].text)\n",
        "        continue\n",
        "\n",
        "      # Since each tag may contain more than one word such as : ['STIRLING', 'SMITH', 'MUSEUM', 'AND', 'ART', 'GALLERY'], ['DEOGAN', 'ROAD']\n",
        "      # ['देवगन', 'रोड']\n",
        "      for word in wordlist1: \n",
        "        English_words.append(word)\n",
        "\n",
        "      for word in wordlist2: \n",
        "        Hindi_words.append(word)\n",
        "\n",
        "    return English_words, Hindi_words\n",
        "\n",
        "  def get_random_sample(self):\n",
        "    return self.__getitem__(np.random.randint(self.__len__()))\n",
        "\n",
        "  # generalise for Hindi and English (array is the parameter that decides if Hindi or English)\n",
        "  def get_batch_from_array(self, batch_size, array):\n",
        "    end = self.shuffle_start_index + batch_size\n",
        "    batch = []\n",
        "    if end >= self.__len__():\n",
        "      batch = [array[i] for i in self.shuffle_indices[0:end%self.__len__()]] # mod if batch size (\"end\") > the length of eng_words in the corpus we got from the XML file\n",
        "      end = self.__len__()\n",
        "    return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index:end]]\n",
        "\n",
        "  def get_batch(self, batch_size, postprocess = True):\n",
        "    eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "    hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "    self.shuffle_start_index += batch_size + 1\n",
        "  \n",
        "    # Reshuffle if 1 epoch is complete\n",
        "    if self.shuffle_start_index >= self.__len__():\n",
        "      random.shuffle(self.shuffle_indices)\n",
        "      self.shuffle_start_index = 0\n",
        "\n",
        "    return eng_batch, hindi_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI6zsl05UQO8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "outputId": "44a0a744-fe67-48b8-8724-cfb23ac7a147"
      },
      "source": [
        "train_data = TransliterationLoader('NEWS2012-Training-EnHi-13937.xml')\n",
        "test_data = TransliterationLoader('NEWS2012-Ref-EnHi-1000.xml')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION - बरहरवा\n",
            "Skipping:  STATE BNK TR - स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST - साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII - किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY - दिबंगवैली\n",
            "Skipping:  ORDER OF VASA - ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD - आज़मनगर\n",
            "Skipping:  CAPE TOWN - केपटाउन\n",
            "Skipping:  NEW ZEALAND - न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES - सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND - राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM - केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY - ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA - जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS - नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA - रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA - फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED - रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR - ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV - ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP - एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE - वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST - व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE - पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC - पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA - मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE - मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC - स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND - न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW - लंदन हीथ्रो\n",
            "Skipping:  RETALIX - रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM - श्री शैलम\n",
            "Skipping:  KARA-KUM - काराकुम\n",
            "Skipping:  WIND RIVER - विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE - नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED - रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT - वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS - कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA - बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG5dpuiPUglk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNIof8hFaWra",
        "colab_type": "text"
      },
      "source": [
        "# Data Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "656wQxzhaZ2C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "4882cd10-e687-4992-b489-fa17658e6964"
      },
      "source": [
        "print(\"Train set size: \", len(train_data))\n",
        "print(\"Test set size: \", len(test_data))\n",
        "\n",
        "print(\"\\nSample data from train set:\")\n",
        "for i in range(10):\n",
        "  eng, hindi = train_data.get_random_sample()\n",
        "  print(eng + '-' + hindi)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set size:  20543\n",
            "Test set size:  1000\n",
            "\n",
            "Sample data from train set:\n",
            "JYOTI-ज्योति\n",
            "JUNCTION-जंक्शन\n",
            "ROUNDER-राउंडर\n",
            "MAGEE-मगी\n",
            "FORT-फोर्ट\n",
            "ROCHEFORT-रॉचेफोर्ट\n",
            "NOOR-नूर\n",
            "MAIL-मेल\n",
            "CANYON-केन्यॉन\n",
            "KHIDASH-खिदाश\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IscIrKxUgB2u",
        "colab_type": "text"
      },
      "source": [
        "(Note all english converted to upper case)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrVYdVTrauCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJA7cymMhIe8",
        "colab_type": "text"
      },
      "source": [
        "# Encoding single words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBYkNaM4hJ80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OHE for English words (input) - convert word to number (OHE main purpose to convert to number)\n",
        "def word_rep( word, letter2index, device = 'cpu'):\n",
        "  rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "  # (number of characters in word, batch in sequence problems, OHE length of each character in vocabulary i.e. 27)\n",
        "  for letter_index, letter in enumerate(word):\n",
        "    pos = letter2index[letter]\n",
        "    rep[letter_index][0][pos] = 1\n",
        "  pad_pos = letter2index[pad_char]\n",
        "  # marking the last character in the word as PAD (remember we made word size = actual word size + 1)\n",
        "  rep[letter_index+1][0][pad_pos] = 1\n",
        "  return rep\n",
        "\n",
        "\n",
        "# Just label for Hindi words (output) sice just classification task\n",
        "def gt_rep(word, letter2index, device = 'cpu'): # ground truth\n",
        "  gt_rep = torch.zeros([len(word)+1, 1], dtype = torch.long).to(device)\n",
        "  for letter_index, letter in enumerate(word):\n",
        "    pos = letter2index[letter]\n",
        "    gt_rep[letter_index][0] =  pos\n",
        "  gt_rep[letter_index + 1][0] = letter2index[pad_char]\n",
        "  return gt_rep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3MA0GlwjzUD",
        "colab_type": "text"
      },
      "source": [
        "Get one pair of (English word, corresponding Hindi word)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPHQTkvYjyOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLsaIG8ajiJs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "1cc83b7d-1cab-43f3-b27c-513abe6dba57"
      },
      "source": [
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, \"\\n\", eng_rep)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KHIDASH \n",
            " tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skF7lKe8kDJ_",
        "colab_type": "text"
      },
      "source": [
        "8 characters including PAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci7RZZ40jtcJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "7e203a31-bf54-41a6-d0a8-19beb01d5866"
      },
      "source": [
        "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, \"\\n\", hindi_gt)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "खिदाश \n",
            " tensor([[23],\n",
            "        [64],\n",
            "        [39],\n",
            "        [63],\n",
            "        [55],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTkPDB8wkQcA",
        "colab_type": "text"
      },
      "source": [
        "6 characters including PAD (kha, i, da, aa, sha, PAD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2vBNRtAkrIZ",
        "colab_type": "text"
      },
      "source": [
        "***NOTE: Number of characters in input need not correspond to number of characters in output. That's the reason we use encoder-decoder architecture***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOHZYI0Ij9K3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPa5L0Z4lT0c",
        "colab_type": "text"
      },
      "source": [
        "# Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoOOHrzPlTtC",
        "colab_type": "text"
      },
      "source": [
        "Note: 3 letters in input (KHI) correspond to two letters in output (kha, i)  \n",
        "Similarly 2 letters in input (SH) correspond to one in output (sha)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqHWzuDMlp-r",
        "colab_type": "text"
      },
      "source": [
        "In such tasks, where output size != input size, need to encode entire input using the encoder part.  \n",
        "And then process it further using the decoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4y6Yf-jo43L",
        "colab_type": "text"
      },
      "source": [
        "## Encoder-Decoder Using GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eleXMZTYle75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size, verbose = False):\n",
        "    # input size is the size of each input character of the word i.e. 27 (OHE)\n",
        "    # output size is the size of each output word character i.e. 118 Hindi characters (Label)\n",
        "    # hidden_size is the number of layers (hyperparameters) of both encoder and decoder RNN cell (needn't be the same, can take 2 parameters for encoder hidden size and decoder hidden size)\n",
        "\n",
        "    super(Transliteration_EncoderDecoder, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    # size of input to encoder cell is input_size\n",
        "    self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "    # size of input to decoder cell is output_size, since the output of the previous timestamp is itself fed to the decoder cell of the current timestamp\n",
        "    self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "\n",
        "    # fully connected\n",
        "    self.h2o = nn.Linear(hidden_size, output_size)\n",
        "    # softmax since classification\n",
        "    self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "    self.verbose = verbose\n",
        "\n",
        "  def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "\n",
        "    # encoder\n",
        "\n",
        "    \"\"\"\n",
        "    Very important:\n",
        "    Encoder is a single GRU/LSTM cell (here, GRU). Now feeding to it (encoding) can be done in 2 ways when sequence (string) problems.\n",
        "    i) Feeding one character (vector size : 27), one at a time. And call it as many times as there are alphabets in the word. Thus input to the GRU once is (1,1,27)\n",
        "    ii) Feeding all the characters at once. In that case, input to GRU is (number of alphabets in word, 1, 27). In one go, computes output of the 6 characters. Internally it happens step wise - i.e. first cell, then output to second cell and so on.\n",
        "    This is possible, since encoding is a simple computation.\n",
        "    The dimension of the \"out\" correspondingly changes.\n",
        "    \"\"\"\n",
        "    out, hidden = self.encoder_rnn_cell(input)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('Encoder input', input.shape)\n",
        "      print('Encoder ouput', out.shape)\n",
        "      print('Encoder hidden', hidden.shape)\n",
        "\n",
        "    # decoder\n",
        "    decoder_state = hidden\n",
        "    decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "    outputs = []\n",
        "\n",
        "    if self.verbose:\n",
        "      print('Decoder state', decoder_state.shape)\n",
        "      print('Decoder input', decoder_input.shape)\n",
        "\n",
        "    for i in range(max_output_chars):\n",
        "\n",
        "      out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Decoder intermediate output', out.shape)\n",
        "\n",
        "      out = self.h2o(decoder_state)\n",
        "      out = self.softmax(out)\n",
        "      outputs.append(out.view(1, -1))\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Decoder output', out.shape)\n",
        "        self.verbose = False\n",
        "      \n",
        "      max_idx = torch.argmax(out, 2, keepdim = True)\n",
        "      if not ground_truth is None:\n",
        "        max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "      one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "      one_hot.zero_()\n",
        "      one_hot.scatter_(2, max_idx, 1)\n",
        "\n",
        "      decoder_input = one_hot.detach()\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHxGJbrzsMMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Chosen number of hidden layers of both encoder and decoder to be 256\n",
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OftZusrFxO92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def infer(network, word, max_chars):\n",
        "  network.eval()\n",
        "  # network = network.__init__(len(eng_alphabets)+1, 256, len(hindi_alphabets)+1)\n",
        "  word = word_rep(word, eng_alpha2index)\n",
        "  print(word)\n",
        "\n",
        "  output = network(word, max_chars)\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGA6QOhesWxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "4cf5ce93-5767-4150-de2e-6823be6ef122"
      },
      "source": [
        "out = infer(net, \"INDIA\", 30)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n",
            "Encoder input torch.Size([6, 1, 27])\n",
            "Encoder ouput torch.Size([6, 1, 256])\n",
            "Encoder hidden torch.Size([1, 1, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 129])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APHsTSJP0qnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}